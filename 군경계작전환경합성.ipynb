{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihyeon602/DeepLearning_practice/blob/main/%EA%B5%B0%EA%B2%BD%EA%B3%84%EC%9E%91%EC%A0%84%ED%99%98%EA%B2%BD%ED%95%A9%EC%84%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba92db4",
      "metadata": {
        "id": "dba92db4"
      },
      "source": [
        "# êµ° ê²½ê³„ ì‘ì „ í™˜ê²½ í•©ì„± ë°ì´í„°\n",
        "- ë¬¸ì œì •ì˜: **ì—¬ëŸ¬ classë¥¼ ì‹¤ì‹œê°„ íƒì§€í•˜ëŠ” ëª¨ë¸ ìƒì„± ë° ì¶”ë¡  í…ŒìŠ¤íŠ¸**\n",
        "\n",
        "- **dataset**: EO(RGB)_SU(í•˜ì ˆê¸°)_DT(ì£¼ê°„) ë°ì´í„°ì…‹ë§Œ ì‚¬ìš©  #ìš©ëŸ‰ì´ìŠˆ\n",
        "  - ì›ë³¸ ê·¸ëŒ€ë¡œ TRAINì€ train valë¡œ êµ¬ì„±\n",
        "\n",
        "- **annotations**: ë¬¸ì„œì— ìˆëŠ” classë§Œ ì‹¤ì‹œê°„ íƒì§€í•˜ë„ë¡ êµ¬ì„±\n",
        "  - GPU ì‚¬ìš© ì œí•œ ì‹œ ìƒ˜í”Œë§â—\n",
        "\n",
        "- **ì‚°ì¶œë¬¼**: modelíŒŒì¼(.pt ë“±), results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0252254",
      "metadata": {
        "id": "f0252254"
      },
      "source": [
        "### ë°ì´í„° ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cb38d01",
      "metadata": {
        "id": "9cb38d01"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file_path = './3.ê°œë°©ë°ì´í„°/1.ë°ì´í„°/Training/02.ë¼ë²¨ë§ë°ì´í„°/TL_EO_SU_DT.zip'\n",
        "extract_to = './AMY/labels_json/train'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"ì••ì¶• í•´ì œ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a57182b",
      "metadata": {
        "id": "7a57182b"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file_path = './3.ê°œë°©ë°ì´í„°/1.ë°ì´í„°/Training/01.ì›ì²œë°ì´í„°/TS_EO_SU_DT.zip'\n",
        "extract_to = './AMY/images/train'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"ì••ì¶• í•´ì œ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5064f07c",
      "metadata": {
        "id": "5064f07c"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file_path = './3.ê°œë°©ë°ì´í„°/1.ë°ì´í„°/Validation/02.ë¼ë²¨ë§ë°ì´í„°/VL_EO_SU_DT.zip'\n",
        "extract_to = './AMY/labels_json/val'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"ì••ì¶• í•´ì œ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac1c116",
      "metadata": {
        "id": "7ac1c116"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file_path = './3.ê°œë°©ë°ì´í„°/1.ë°ì´í„°/Validation/01.ì›ì²œë°ì´í„°/VS_EO_SU_DT.zip'\n",
        "extract_to = './AMY/images/val'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"ì••ì¶• í•´ì œ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a97d3b8",
      "metadata": {
        "id": "1a97d3b8"
      },
      "source": [
        "### json íŒŒì¼ yolo í¬ë§·(.txt) íŒŒì¼ë¡œ ë³€í™˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a8c833b",
      "metadata": {
        "id": "9a8c833b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "# ê¸°ë³¸ ê²½ë¡œ\n",
        "base_path = \"./3.ê°œë°©ë°ì´í„°/1.ë°ì´í„°\"\n",
        "\n",
        "# ê²½ë¡œ ë”•ì…”ë„ˆë¦¬\n",
        "sets = {\n",
        "    'train': {\n",
        "        'json_folder': os.path.join(base_path, \"labels_json\", \"train\"),   # JSON ë¼ë²¨\n",
        "        'image_folder': os.path.join(base_path, \"images\", \"train\"),  # ì´ë¯¸ì§€\n",
        "        'output_folder': os.path.join(base_path, \"labels\", \"train\")  # YOLO í˜•ì‹ ì €ì¥ë  ìœ„ì¹˜\n",
        "    },\n",
        "    'val': {\n",
        "        'json_folder': os.path.join(base_path, \"labels_json\", \"val\"),\n",
        "        'image_folder': os.path.join(base_path, \"images\", \"val\"),\n",
        "        'output_folder': os.path.join(base_path, \"labels\", \"val\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# ì§€ì› ì´ë¯¸ì§€ í™•ì¥ì\n",
        "image_exts = ['.jpg', '.jpeg', '.png']\n",
        "\n",
        "# ë³€í™˜ í•¨ìˆ˜ ì •ì˜\n",
        "def convert_to_yolo(json_folder, image_folder, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for file in os.listdir(json_folder):\n",
        "        if file.endswith('.json'):\n",
        "            base_name = os.path.splitext(file)[0]\n",
        "\n",
        "            # JSON ë¡œë“œ\n",
        "            with open(os.path.join(json_folder, file), 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # ì´ë¯¸ì§€ ì°¾ê¸°\n",
        "            image_path = None\n",
        "            for ext in image_exts:\n",
        "                candidate = os.path.join(image_folder, base_name + ext)\n",
        "                if os.path.exists(candidate):\n",
        "                    image_path = candidate\n",
        "                    break\n",
        "\n",
        "            if not image_path:\n",
        "                print(f\"âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ: {base_name}\")\n",
        "                continue\n",
        "\n",
        "            # ì´ë¯¸ì§€ í¬ê¸°\n",
        "            with Image.open(image_path) as img:\n",
        "                img_width, img_height = img.size\n",
        "\n",
        "            yolo_lines = []\n",
        "            for ann in data.get(\"annotations\", []):\n",
        "                if ann.get(\"shape\") == \"Bounding Box\":\n",
        "                    (x1, y1), (x2, y2) = ann[\"points\"]\n",
        "                    cx = (x1 + x2) / 2 / img_width\n",
        "                    cy = (y1 + y2) / 2 / img_height\n",
        "                    w = abs(x2 - x1) / img_width\n",
        "                    h = abs(y2 - y1) / img_height\n",
        "                    yolo_lines.append(f\"0 {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\")\n",
        "\n",
        "            # ê²°ê³¼ ì €ì¥\n",
        "            out_path = os.path.join(output_folder, base_name + \".txt\")\n",
        "            with open(out_path, \"w\", encoding='utf-8') as f:\n",
        "                f.write(\"\\n\".join(yolo_lines))\n",
        "\n",
        "            print(f\"âœ… ë³€í™˜ ì™„ë£Œ: {base_name}.txt\")\n",
        "\n",
        "# â–¶ ê° ì„¸íŠ¸(train, val)ì— ëŒ€í•´ ì‹¤í–‰\n",
        "for phase, paths in sets.items():\n",
        "    print(f\"\\nğŸ“‚ ì²˜ë¦¬ ì¤‘: {phase}\")\n",
        "    convert_to_yolo(paths['json_folder'], paths['image_folder'], paths['output_folder'])\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}